{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbUih33HQZr1",
        "outputId": "93e45e71-e37b-40e4-ca45-ae7b2ae287e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Connect google drive to Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCNuKELvQaef",
        "outputId": "b12fdbc3-7f5d-4ee1-f26a-c14bb2504262"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gym==0.21.0\n",
            "  Downloading gym-0.21.0.tar.gz (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 14.9 MB/s \n",
            "\u001b[?25hCollecting gym-retro\n",
            "  Downloading gym_retro-0.8.0-cp38-cp38-manylinux1_x86_64.whl (161.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 161.9 MB 65 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.8/dist-packages (from gym==0.21.0) (1.21.6)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gym==0.21.0) (1.5.0)\n",
            "Collecting pyglet==1.*,>=1.3.2\n",
            "  Downloading pyglet-1.5.27-py3-none-any.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 62.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: gym\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616824 sha256=3e017f9a90ee5b153b667ca8d91a0d58eb11fcc2ffa0ef241b7f0d3e8d8d76d0\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/6d/b3/a3a6e10704795c9b9000f1ab2dc480dfe7bed42f5972806e73\n",
            "Successfully built gym\n",
            "Installing collected packages: pyglet, gym, gym-retro\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "Successfully installed gym-0.21.0 gym-retro-0.8.0 pyglet-1.5.27\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (4.6.0.66)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from opencv-python) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/cu113/torch_stable.html\n",
            "Collecting torch==1.10.2+cu113\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torch-1.10.2%2Bcu113-cp38-cp38-linux_x86_64.whl (1821.4 MB)\n",
            "\u001b[K     |██████████████▋                 | 834.1 MB 1.2 MB/s eta 0:13:31tcmalloc: large alloc 1147494400 bytes == 0x39fb6000 @  0x7f38cdb7c615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n",
            "\u001b[K     |██████████████████▌             | 1055.7 MB 1.3 MB/s eta 0:09:51tcmalloc: large alloc 1434370048 bytes == 0x7e60c000 @  0x7f38cdb7c615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n",
            "\u001b[K     |███████████████████████▌        | 1336.2 MB 1.2 MB/s eta 0:06:39tcmalloc: large alloc 1792966656 bytes == 0x343e000 @  0x7f38cdb7c615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n",
            "\u001b[K     |█████████████████████████████▊  | 1691.1 MB 1.2 MB/s eta 0:01:49tcmalloc: large alloc 2241208320 bytes == 0x6e226000 @  0x7f38cdb7c615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n",
            "\u001b[K     |████████████████████████████████| 1821.4 MB 1.2 MB/s eta 0:00:01tcmalloc: large alloc 1821450240 bytes == 0xf3b88000 @  0x7f38cdb7b1e7 0x4d30a0 0x4d312c 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91 0x5d8941 0x49abe4 0x4fd8b5 0x49abe4 0x55cd91\n",
            "tcmalloc: large alloc 2276818944 bytes == 0x16049a000 @  0x7f38cdb7c615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91 0x5d8941 0x49abe4 0x4fd8b5 0x49abe4 0x55cd91 0x5d8941 0x4fe318\n",
            "\u001b[K     |████████████████████████████████| 1821.4 MB 2.0 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.11.3+cu113\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torchvision-0.11.3%2Bcu113-cp38-cp38-linux_x86_64.whl (24.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.5 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting torchaudio===0.10.2+cu113\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torchaudio-0.10.2%2Bcu113-cp38-cp38-linux_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 45.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.10.2+cu113) (4.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision==0.11.3+cu113) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.11.3+cu113) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.0+cu116\n",
            "    Uninstalling torch-1.13.0+cu116:\n",
            "      Successfully uninstalled torch-1.13.0+cu116\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.14.0+cu116\n",
            "    Uninstalling torchvision-0.14.0+cu116:\n",
            "      Successfully uninstalled torchvision-0.14.0+cu116\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.13.0+cu116\n",
            "    Uninstalling torchaudio-0.13.0+cu116:\n",
            "      Successfully uninstalled torchaudio-0.13.0+cu116\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.14.0 requires torch==1.13.0, but you have torch 1.10.2+cu113 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.10.2+cu113 torchaudio-0.10.2+cu113 torchvision-0.11.3+cu113\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting stable-baselines3[extra]\n",
            "  Downloading stable_baselines3-1.6.2-py3-none-any.whl (170 kB)\n",
            "\u001b[K     |████████████████████████████████| 170 kB 16.2 MB/s \n",
            "\u001b[?25hCollecting optuna\n",
            "  Downloading optuna-3.0.5-py3-none-any.whl (348 kB)\n",
            "\u001b[K     |████████████████████████████████| 348 kB 70.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (1.4.45)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from optuna) (1.21.6)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.9.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from optuna) (4.64.1)\n",
            "Collecting cliff\n",
            "  Downloading cliff-4.1.0-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 8.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: scipy<1.9.0,>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (1.7.3)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (21.3)\n",
            "Collecting alembic>=1.5.0\n",
            "  Downloading alembic-1.9.0-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 81.9 MB/s \n",
            "\u001b[?25hCollecting importlib-metadata<5.0.0\n",
            "  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 9.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from alembic>=1.5.0->optuna) (5.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata<5.0.0->optuna) (3.11.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.8/dist-packages (from cliff->optuna) (3.5.0)\n",
            "Collecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Collecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.2-py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 79.8 MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-4.1.1-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.8/dist-packages (from cmd2>=1.0.0->cliff->optuna) (22.1.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.8/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.11.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 71.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.8/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from stable-baselines3[extra]) (3.2.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from stable-baselines3[extra]) (1.5.0)\n",
            "Collecting torch>=1.11\n",
            "  Downloading torch-1.13.1-cp38-cp38-manylinux1_x86_64.whl (887.4 MB)\n",
            "\u001b[K     |██████████████████████████████  | 834.1 MB 1.2 MB/s eta 0:00:46tcmalloc: large alloc 1147494400 bytes == 0x3aaaa000 @  0x7f7cd4cf5615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n",
            "\u001b[K     |████████████████████████████████| 887.4 MB 1.7 kB/s \n",
            "\u001b[?25hRequirement already satisfied: gym==0.21 in /usr/local/lib/python3.8/dist-packages (from stable-baselines3[extra]) (0.21.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from stable-baselines3[extra]) (1.3.5)\n",
            "Collecting rich\n",
            "  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n",
            "\u001b[K     |████████████████████████████████| 237 kB 71.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from stable-baselines3[extra]) (7.1.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (from stable-baselines3[extra]) (4.6.0.66)\n",
            "Collecting autorom[accept-rom-license]~=0.4.2\n",
            "  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from stable-baselines3[extra]) (5.4.8)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.8/dist-packages (from stable-baselines3[extra]) (2.9.1)\n",
            "Collecting ale-py==0.7.4\n",
            "  Downloading ale_py-0.7.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 58.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.23.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (7.1.2)\n",
            "Collecting AutoROM.accept-rom-license\n",
            "  Downloading AutoROM.accept-rom-license-0.5.0.tar.gz (10 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (57.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.15.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.51.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.38.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.6.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.19.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.4.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.2.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->stable-baselines3[extra]) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2022.12.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.2.2)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[K     |████████████████████████████████| 849 kB 57.6 MB/s \n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.0 MB 89.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.11->stable-baselines3[extra]) (4.4.0)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 317.1 MB 33 kB/s \n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 557.1 MB 11 kB/s \n",
            "\u001b[?25hCollecting libtorrent\n",
            "  Using cached libtorrent-2.0.7-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (8.6 MB)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->stable-baselines3[extra]) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->stable-baselines3[extra]) (2022.6)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 9.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.8/dist-packages (from rich->stable-baselines3[extra]) (2.6.1)\n",
            "Building wheels for collected packages: pyperclip, AutoROM.accept-rom-license\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11136 sha256=ac0b9138ac00ee5a56b1f18aa44e5784950890ed37c790038793368609e1e576\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/1a/65/84ff8c386bec21fca6d220ea1f5498a0367883a78dd5ba6122\n",
            "  Building wheel for AutoROM.accept-rom-license (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.5.0-py3-none-any.whl size=440868 sha256=01456e524b9316e4dbf132fcc243936c5d8fd043d53dc2abca3c91d18ea394be\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/c9/25/578470ae932b494c313dc22e6c57afff192140fb3cd5acf185\n",
            "Successfully built pyperclip AutoROM.accept-rom-license\n",
            "Installing collected packages: nvidia-cublas-cu11, pyperclip, pbr, nvidia-cudnn-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, libtorrent, importlib-metadata, torch, stevedore, Mako, commonmark, cmd2, AutoROM.accept-rom-license, autorom, autopage, stable-baselines3, rich, colorlog, cmaes, cliff, alembic, ale-py, optuna\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 5.1.0\n",
            "    Uninstalling importlib-metadata-5.1.0:\n",
            "      Successfully uninstalled importlib-metadata-5.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.2+cu113\n",
            "    Uninstalling torch-1.10.2+cu113:\n",
            "      Successfully uninstalled torch-1.10.2+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.3+cu113 requires torch==1.10.2, but you have torch 1.13.1 which is incompatible.\n",
            "torchtext 0.14.0 requires torch==1.13.0, but you have torch 1.13.1 which is incompatible.\n",
            "torchaudio 0.10.2+cu113 requires torch==1.10.2, but you have torch 1.13.1 which is incompatible.\u001b[0m\n",
            "Successfully installed AutoROM.accept-rom-license-0.5.0 Mako-1.2.4 ale-py-0.7.4 alembic-1.9.0 autopage-0.5.1 autorom-0.4.2 cliff-4.1.0 cmaes-0.9.0 cmd2-2.4.2 colorlog-6.7.0 commonmark-0.9.1 importlib-metadata-4.13.0 libtorrent-2.0.7 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 optuna-3.0.5 pbr-5.11.0 pyperclip-1.8.2 rich-12.6.0 stable-baselines3-1.6.2 stevedore-4.1.1 torch-1.13.1\n"
          ]
        }
      ],
      "source": [
        "# Install the environment\n",
        "!pip install gym==0.21.0 gym-retro\n",
        "!pip install opencv-python\n",
        "!pip install torch==1.10.2+cu113 torchvision==0.11.3+cu113 torchaudio===0.10.2+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html\n",
        "!pip install stable-baselines3[extra] optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OQDsj5cjQixz"
      },
      "outputs": [],
      "source": [
        "# Import the externel module\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import retro\n",
        "import time\n",
        "import optuna\n",
        "from gym import Env \n",
        "from gym.spaces import MultiBinary, Box\n",
        "# PPO -> Reinforcement Learning Model we will use\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack\n",
        "# from stable_baselines.common.policies import MlpPolicy, MlpLstmPolicy, MlpLnLstmPolicy, CnnLnLstmPolicy, CnnPolicy, CnnLstmPolicy\n",
        "# from stable_baselines.common.vec_env import SubprocVecEnv, DummyVecEnv\n",
        "# from stable_baselines import PPO2, A2C\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eRM8gMuZc0hl"
      },
      "outputs": [],
      "source": [
        "class StreetFighter(Env): \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Observation_space size reduction : 200 x 256 x 3 -> 84 x 84 x 1\n",
        "        self.observation_space = Box(low=0, high=255, shape=(84, 84, 1), dtype=np.uint8)\n",
        "        # Stop(1) / Move(5) : Left, Right, Block, Jump, Crouch / Attack(6) : Punch level x3, Kick level x3\n",
        "        self.action_space = MultiBinary(12)\n",
        "        self.game = retro.make(game='StreetFighterIISpecialChampionEdition-Genesis', use_restricted_actions=retro.Actions.FILTERED)\n",
        "    \n",
        "    def preprocess(self, obs): \n",
        "        obs_gray = cv2.cvtColor(obs, cv2.COLOR_BGR2GRAY)\n",
        "        obs_channels = np.reshape(cv2.resize(obs_gray, (84,84), interpolation=cv2.INTER_CUBIC), (84,84,1))\n",
        "        return obs_channels \n",
        "\n",
        "    def reset(self):\n",
        "        obs = self.game.reset()\n",
        "        obs = self.preprocess(obs) \n",
        "        self.previous_frame = obs \n",
        "        self.score = 0\n",
        "        return obs\n",
        "    \n",
        "    def step(self, action): \n",
        "        obs, reward, done, info = self.game.step(action)\n",
        "        obs = self.preprocess(obs) \n",
        "        frame_delta = obs - self.previous_frame\n",
        "        self.previous_frame = obs\n",
        "        reward = info['score'] - self.score \n",
        "        self.score = info['score'] \n",
        "        return frame_delta, reward, done, info\n",
        "    \n",
        "    def render(self, *args, **kwargs):\n",
        "        self.game.render()\n",
        "        \n",
        "    def close(self):\n",
        "        self.game.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pd6ngagJlpy2"
      },
      "outputs": [],
      "source": [
        "class Callback(BaseCallback):\n",
        "\n",
        "    def __init__(self, period, save_dir, verbose=1):\n",
        "        super(Callback, self).__init__(verbose)\n",
        "        self.period = period\n",
        "        self.save_dir = save_dir\n",
        "\n",
        "    def _init_callback(self):\n",
        "        if os.path.isdir(self.save_dir) == False:\n",
        "            os.makedirs(self.save_dir)\n",
        "        # if self.save_dir is not None:\n",
        "        #     os.makedirs(self.save_dir, exist_ok=True)\n",
        "\n",
        "    def _on_step(self):\n",
        "        if self.n_calls % self.period == 0:\n",
        "            self.model.save(os.path.join(self.save_dir, 'best_model_{}'.format(self.n_calls)))\n",
        "\n",
        "        return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Coy5yYzudk0-"
      },
      "outputs": [],
      "source": [
        "def HypParam_PPO(trial): \n",
        "    return {\n",
        "        'n_steps':trial.suggest_int('n_steps', 2048, 8192),\n",
        "        'gamma':trial.suggest_loguniform('gamma', 0.8, 0.9999),\n",
        "        'learning_rate':trial.suggest_loguniform('learning_rate', 1e-5, 1e-4),\n",
        "        'clip_range':trial.suggest_uniform('clip_range', 0.1, 0.4),\n",
        "        'gae_lambda':trial.suggest_uniform('gae_lambda', 0.8, 0.99)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "1qGn5Etbdntk"
      },
      "outputs": [],
      "source": [
        "# Create the Model to optization from Optuna\n",
        "def PPO_agent(trial):\n",
        "    model_params = HypParam_PPO(trial) \n",
        "\n",
        "    env = StreetFighter()\n",
        "    env = Monitor(env, LOG_DIR)\n",
        "    env = DummyVecEnv([lambda: env])\n",
        "    env = VecFrameStack(env, 4, channels_order='last')\n",
        "\n",
        "    model = PPO('CnnPolicy', env, tensorboard_log=LOG_DIR, verbose=0, **model_params)\n",
        "    model.learn(total_timesteps=30000)\n",
        "\n",
        "    mean_reward, _ = evaluate_policy(model, env, n_eval_episodes=5)\n",
        "    env.close()\n",
        "\n",
        "    model.save(os.path.join(OPT_DIR, 'No.{}_best_model'.format(trial.number)))\n",
        "\n",
        "    return mean_reward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLUZ--1jVome",
        "outputId": "8909d046-4761-4451-b2d2-40c9f166e823"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Importing StreetFighterIISpecialChampionEdition-Genesis\n",
            "Imported 1 games\n"
          ]
        }
      ],
      "source": [
        "# Retro import the Street Fighter ROM file\n",
        "!python -m retro.import \"/content/drive/MyDrive/RL\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "XVvQzM0cdL7n"
      },
      "outputs": [],
      "source": [
        "# Define the Directories\n",
        "LOG_DIR = '/content/drive/MyDrive/RL/logs/'\n",
        "OPT_DIR = '/content/drive/MyDrive/RL/opt/'\n",
        "SAVE_PATH = os.path.join(OPT_DIR, 'No.{}_best_model'.format(1))\n",
        "CHECKPOINT_DIR = './train/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rPvyfpMdo5w",
        "outputId": "3ccb0870-8ade-441b-f2ce-53151474468b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-12-23 12:06:18,416]\u001b[0m A new study created in memory with name: no-name-e319bbed-a07d-4553-9d37-811e095d7c64\u001b[0m\n",
            "<ipython-input-6-05bdd534a7ad>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'gamma':trial.suggest_loguniform('gamma', 0.8, 0.9999),\n",
            "<ipython-input-6-05bdd534a7ad>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'learning_rate':trial.suggest_loguniform('learning_rate', 1e-5, 1e-4),\n",
            "<ipython-input-6-05bdd534a7ad>:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'clip_range':trial.suggest_uniform('clip_range', 0.1, 0.4),\n",
            "<ipython-input-6-05bdd534a7ad>:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'gae_lambda':trial.suggest_uniform('gae_lambda', 0.8, 0.99)\n",
            "/usr/local/lib/python3.8/dist-packages/stable_baselines3/ppo/ppo.py:151: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 4761`, after every 74 untruncated mini-batches, there will be a truncated mini-batch of size 25\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=4761 and n_envs=1)\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-12-23 12:10:06,873]\u001b[0m Trial 0 finished with value: 0.0 and parameters: {'n_steps': 4761, 'gamma': 0.9380136088650449, 'learning_rate': 9.911324242139609e-05, 'clip_range': 0.3196227652016298, 'gae_lambda': 0.9619233930716062}. Best is trial 0 with value: 0.0.\u001b[0m\n",
            "/usr/local/lib/python3.8/dist-packages/stable_baselines3/ppo/ppo.py:151: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 2127`, after every 33 untruncated mini-batches, there will be a truncated mini-batch of size 15\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=2127 and n_envs=1)\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-12-23 12:14:03,862]\u001b[0m Trial 1 finished with value: 0.0 and parameters: {'n_steps': 2127, 'gamma': 0.8251011235595651, 'learning_rate': 6.677573004995199e-05, 'clip_range': 0.2333552500369341, 'gae_lambda': 0.9549917136610048}. Best is trial 0 with value: 0.0.\u001b[0m\n",
            "/usr/local/lib/python3.8/dist-packages/stable_baselines3/ppo/ppo.py:151: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 3898`, after every 60 untruncated mini-batches, there will be a truncated mini-batch of size 58\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=3898 and n_envs=1)\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-12-23 12:18:53,605]\u001b[0m Trial 2 finished with value: 12300.0 and parameters: {'n_steps': 3898, 'gamma': 0.8087624135220374, 'learning_rate': 6.968186384976654e-05, 'clip_range': 0.16784859097079108, 'gae_lambda': 0.9470416578746417}. Best is trial 2 with value: 12300.0.\u001b[0m\n",
            "/usr/local/lib/python3.8/dist-packages/stable_baselines3/ppo/ppo.py:151: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 5331`, after every 83 untruncated mini-batches, there will be a truncated mini-batch of size 19\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=5331 and n_envs=1)\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-12-23 12:22:37,536]\u001b[0m Trial 3 finished with value: 1000.0 and parameters: {'n_steps': 5331, 'gamma': 0.8683320794964452, 'learning_rate': 1.006400108206739e-05, 'clip_range': 0.2370285829108671, 'gae_lambda': 0.9558769046671185}. Best is trial 2 with value: 12300.0.\u001b[0m\n",
            "/usr/local/lib/python3.8/dist-packages/stable_baselines3/ppo/ppo.py:151: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 3664`, after every 57 untruncated mini-batches, there will be a truncated mini-batch of size 16\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=3664 and n_envs=1)\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-12-23 12:26:39,839]\u001b[0m Trial 4 finished with value: 0.0 and parameters: {'n_steps': 3664, 'gamma': 0.9688868630635545, 'learning_rate': 1.4509502124602976e-05, 'clip_range': 0.25700414234098634, 'gae_lambda': 0.8570543004883526}. Best is trial 2 with value: 12300.0.\u001b[0m\n",
            "/usr/local/lib/python3.8/dist-packages/stable_baselines3/ppo/ppo.py:151: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 2607`, after every 40 untruncated mini-batches, there will be a truncated mini-batch of size 47\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=2607 and n_envs=1)\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-12-23 12:30:40,741]\u001b[0m Trial 5 finished with value: 0.0 and parameters: {'n_steps': 2607, 'gamma': 0.9883979715674043, 'learning_rate': 7.801494539791737e-05, 'clip_range': 0.1931252052870679, 'gae_lambda': 0.8898912520476957}. Best is trial 2 with value: 12300.0.\u001b[0m\n",
            "/usr/local/lib/python3.8/dist-packages/stable_baselines3/ppo/ppo.py:151: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 7784`, after every 121 untruncated mini-batches, there will be a truncated mini-batch of size 40\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=7784 and n_envs=1)\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-12-23 12:34:36,746]\u001b[0m Trial 6 finished with value: 2000.0 and parameters: {'n_steps': 7784, 'gamma': 0.922512749722004, 'learning_rate': 1.9709855043529815e-05, 'clip_range': 0.203901143208254, 'gae_lambda': 0.8022911062954894}. Best is trial 2 with value: 12300.0.\u001b[0m\n",
            "/usr/local/lib/python3.8/dist-packages/stable_baselines3/ppo/ppo.py:151: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 4171`, after every 65 untruncated mini-batches, there will be a truncated mini-batch of size 11\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=4171 and n_envs=1)\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-12-23 12:38:42,521]\u001b[0m Trial 7 finished with value: 2000.0 and parameters: {'n_steps': 4171, 'gamma': 0.9095906861437366, 'learning_rate': 2.230877755964239e-05, 'clip_range': 0.21565802486282737, 'gae_lambda': 0.9259825842432137}. Best is trial 2 with value: 12300.0.\u001b[0m\n",
            "/usr/local/lib/python3.8/dist-packages/stable_baselines3/ppo/ppo.py:151: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 7613`, after every 118 untruncated mini-batches, there will be a truncated mini-batch of size 61\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=7613 and n_envs=1)\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-12-23 12:42:45,802]\u001b[0m Trial 8 finished with value: 12700.0 and parameters: {'n_steps': 7613, 'gamma': 0.906305450231301, 'learning_rate': 1.590696426359432e-05, 'clip_range': 0.3653015121517822, 'gae_lambda': 0.9047694783029425}. Best is trial 8 with value: 12700.0.\u001b[0m\n",
            "/usr/local/lib/python3.8/dist-packages/stable_baselines3/ppo/ppo.py:151: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 2194`, after every 34 untruncated mini-batches, there will be a truncated mini-batch of size 18\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=2194 and n_envs=1)\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2022-12-23 12:47:05,398]\u001b[0m Trial 9 finished with value: 2500.0 and parameters: {'n_steps': 2194, 'gamma': 0.8267444843003067, 'learning_rate': 8.451338764959314e-05, 'clip_range': 0.3720741153407311, 'gae_lambda': 0.8525143325456295}. Best is trial 8 with value: 12700.0.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Creating the experiment and Execute the optimization\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(PPO_agent, n_trials=10, n_jobs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVi2pJRyenay",
        "outputId": "49c0448a-b91a-4f60-f320-f12085d1ce72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_steps': 7613, 'gamma': 0.906305450231301, 'learning_rate': 1.590696426359432e-05, 'clip_range': 0.3653015121517822, 'gae_lambda': 0.9047694783029425}\n"
          ]
        }
      ],
      "source": [
        "# Tunning the hyperparameters\n",
        "print(study.best_params)\n",
        "model = PPO.load(os.path.join(OPT_DIR, 'No.8_best_model'))\n",
        "callback = Callback(period=10000, save_dir=CHECKPOINT_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "l-KxQ3Fal13M",
        "outputId": "91cad547-6cab-4dc4-e2d8-7ec2dc45129d"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-a05b9b92747b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStreetFighter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-812364f688b8>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# Stop(1) / Move(5) : Left, Right, Block, Jump, Crouch / Attack(6) : Punch level x3, Kick level x3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiBinary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'StreetFighterIISpecialChampionEdition-Genesis'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_restricted_actions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mActions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFILTERED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/retro/__init__.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(game, state, inttype, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Game not found: %s. Did you make sure to import the ROM?'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mRetroEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minttype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minttype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/retro/retro_env.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, game, state, scenario, info, use_restricted_actions, record, players, inttype, obs_type)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# emulator, ensure that unused ones are garbage-collected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRetroEmulator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrom_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigure_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Cannot create multiple emulator instances per process, make sure to call env.close() on each environment before creating a new one"
          ]
        }
      ],
      "source": [
        "env = StreetFighter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYBgQrrwviL4",
        "outputId": "56f19b8f-b7ff-41a8-c8af-bf9b2a687b53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env in a VecTransposeImage.\n",
            "Logging to /content/drive/MyDrive/RL/logs/PPO_12\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 399  |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 19   |\n",
            "|    total_timesteps | 7613 |\n",
            "-----------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.11e+04    |\n",
            "|    ep_rew_mean          | 3.51e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 319         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 47          |\n",
            "|    total_timesteps      | 15226       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017843114 |\n",
            "|    clip_fraction        | 0.0207      |\n",
            "|    clip_range           | 0.365       |\n",
            "|    entropy_loss         | -8.31       |\n",
            "|    explained_variance   | 2.62e-06    |\n",
            "|    learning_rate        | 1.59e-05    |\n",
            "|    loss                 | 655         |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0014     |\n",
            "|    value_loss           | 7.25e+04    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1.11e+04   |\n",
            "|    ep_rew_mean          | 3.51e+04   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 303        |\n",
            "|    iterations           | 3          |\n",
            "|    time_elapsed         | 75         |\n",
            "|    total_timesteps      | 22839      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01521108 |\n",
            "|    clip_fraction        | 0.0343     |\n",
            "|    clip_range           | 0.365      |\n",
            "|    entropy_loss         | -8.3       |\n",
            "|    explained_variance   | 8.58e-06   |\n",
            "|    learning_rate        | 1.59e-05   |\n",
            "|    loss                 | 57.3       |\n",
            "|    n_updates            | 20         |\n",
            "|    policy_gradient_loss | -0.00318   |\n",
            "|    value_loss           | 1.43e+05   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.14e+04    |\n",
            "|    ep_rew_mean          | 4.62e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 296         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 102         |\n",
            "|    total_timesteps      | 30452       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017487863 |\n",
            "|    clip_fraction        | 0.0369      |\n",
            "|    clip_range           | 0.365       |\n",
            "|    entropy_loss         | -8.29       |\n",
            "|    explained_variance   | 0.00194     |\n",
            "|    learning_rate        | 1.59e-05    |\n",
            "|    loss                 | 39.9        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.00327    |\n",
            "|    value_loss           | 1.4e+04     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.09e+04    |\n",
            "|    ep_rew_mean          | 4.62e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 293         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 129         |\n",
            "|    total_timesteps      | 38065       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016451605 |\n",
            "|    clip_fraction        | 0.0428      |\n",
            "|    clip_range           | 0.365       |\n",
            "|    entropy_loss         | -8.27       |\n",
            "|    explained_variance   | 0.00118     |\n",
            "|    learning_rate        | 1.59e-05    |\n",
            "|    loss                 | 71.5        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0011     |\n",
            "|    value_loss           | 1.57e+05    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1.06e+04   |\n",
            "|    ep_rew_mean          | 4.21e+04   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 290        |\n",
            "|    iterations           | 6          |\n",
            "|    time_elapsed         | 157        |\n",
            "|    total_timesteps      | 45678      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01934216 |\n",
            "|    clip_fraction        | 0.0572     |\n",
            "|    clip_range           | 0.365      |\n",
            "|    entropy_loss         | -8.26      |\n",
            "|    explained_variance   | 0.00288    |\n",
            "|    learning_rate        | 1.59e-05   |\n",
            "|    loss                 | 123        |\n",
            "|    n_updates            | 50         |\n",
            "|    policy_gradient_loss | -0.00269   |\n",
            "|    value_loss           | 6.51e+04   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 9.68e+03    |\n",
            "|    ep_rew_mean          | 3.53e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 289         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 184         |\n",
            "|    total_timesteps      | 53291       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018416662 |\n",
            "|    clip_fraction        | 0.0663      |\n",
            "|    clip_range           | 0.365       |\n",
            "|    entropy_loss         | -8.22       |\n",
            "|    explained_variance   | -0.00947    |\n",
            "|    learning_rate        | 1.59e-05    |\n",
            "|    loss                 | 2.58e+03    |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.00475    |\n",
            "|    value_loss           | 1.73e+03    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 9.88e+03    |\n",
            "|    ep_rew_mean          | 3.51e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 286         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 212         |\n",
            "|    total_timesteps      | 60904       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018616585 |\n",
            "|    clip_fraction        | 0.0518      |\n",
            "|    clip_range           | 0.365       |\n",
            "|    entropy_loss         | -8.23       |\n",
            "|    explained_variance   | 0.00157     |\n",
            "|    learning_rate        | 1.59e-05    |\n",
            "|    loss                 | 707         |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.00324    |\n",
            "|    value_loss           | 5.47e+04    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 9.88e+03   |\n",
            "|    ep_rew_mean          | 3.51e+04   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 285        |\n",
            "|    iterations           | 9          |\n",
            "|    time_elapsed         | 240        |\n",
            "|    total_timesteps      | 68517      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02028088 |\n",
            "|    clip_fraction        | 0.0499     |\n",
            "|    clip_range           | 0.365      |\n",
            "|    entropy_loss         | -8.24      |\n",
            "|    explained_variance   | 0.00546    |\n",
            "|    learning_rate        | 1.59e-05   |\n",
            "|    loss                 | 41.9       |\n",
            "|    n_updates            | 80         |\n",
            "|    policy_gradient_loss | -0.00599   |\n",
            "|    value_loss           | 2.03e+04   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.05e+04    |\n",
            "|    ep_rew_mean          | 3.61e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 284         |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 267         |\n",
            "|    total_timesteps      | 76130       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024146158 |\n",
            "|    clip_fraction        | 0.0585      |\n",
            "|    clip_range           | 0.365       |\n",
            "|    entropy_loss         | -8.21       |\n",
            "|    explained_variance   | 0.00327     |\n",
            "|    learning_rate        | 1.59e-05    |\n",
            "|    loss                 | 40.9        |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.0045     |\n",
            "|    value_loss           | 5.95e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.05e+04    |\n",
            "|    ep_rew_mean          | 3.61e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 284         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 294         |\n",
            "|    total_timesteps      | 83743       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.025935672 |\n",
            "|    clip_fraction        | 0.0725      |\n",
            "|    clip_range           | 0.365       |\n",
            "|    entropy_loss         | -8.2        |\n",
            "|    explained_variance   | 0.00377     |\n",
            "|    learning_rate        | 1.59e-05    |\n",
            "|    loss                 | 1.56e+03    |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.00426    |\n",
            "|    value_loss           | 4.42e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 9.92e+03    |\n",
            "|    ep_rew_mean          | 3.08e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 283         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 321         |\n",
            "|    total_timesteps      | 91356       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024910407 |\n",
            "|    clip_fraction        | 0.0719      |\n",
            "|    clip_range           | 0.365       |\n",
            "|    entropy_loss         | -8.17       |\n",
            "|    explained_variance   | 0.00849     |\n",
            "|    learning_rate        | 1.59e-05    |\n",
            "|    loss                 | 201         |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.00377    |\n",
            "|    value_loss           | 1.99e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 9.92e+03    |\n",
            "|    ep_rew_mean          | 3.08e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 283         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 349         |\n",
            "|    total_timesteps      | 98969       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.027071815 |\n",
            "|    clip_fraction        | 0.0608      |\n",
            "|    clip_range           | 0.365       |\n",
            "|    entropy_loss         | -8.12       |\n",
            "|    explained_variance   | 0.00672     |\n",
            "|    learning_rate        | 1.59e-05    |\n",
            "|    loss                 | 2.45e+03    |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.00104    |\n",
            "|    value_loss           | 7.29e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.01e+04    |\n",
            "|    ep_rew_mean          | 3.21e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 281         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 378         |\n",
            "|    total_timesteps      | 106582      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.026817268 |\n",
            "|    clip_fraction        | 0.086       |\n",
            "|    clip_range           | 0.365       |\n",
            "|    entropy_loss         | -8.08       |\n",
            "|    explained_variance   | 0.00977     |\n",
            "|    learning_rate        | 1.59e-05    |\n",
            "|    loss                 | 51.5        |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.00607    |\n",
            "|    value_loss           | 6.45e+04    |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<stable_baselines3.ppo.ppo.PPO at 0x7f78d813f1f0>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Training the model with Best hyperparameters\n",
        "model_params = study.best_params\n",
        "model = PPO('CnnPolicy', env, tensorboard_log=LOG_DIR, verbose=1, **model_params)\n",
        "model.load(os.path.join(OPT_DIR, 'No.8_best_model'))\n",
        "model.learn(total_timesteps=100000, callback=callback)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2V3kwKQjDyeA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
